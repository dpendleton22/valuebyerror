{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Data Cleaning & Pipelines\"\n",
    "> \"It's not the sexiest part of data science but it is probably the most important\"\n",
    "\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [data cleaning, data preparation, pandas.pipe, NBA]\n",
    "- image: https://media.giphy.com/media/Qvpxb0bju1rEp9Nipy/giphy.gif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Jist: Data Cleaning is critical before developing a model\n",
    "The data exploration post showed how to use knowledge about a dataset to interpret information. Since we know how the 2017-2019 seasons went for the Milwuakee Bucks and Sacramento Kings we can now plan out our machine learning problem. The machine learning model will attempt to predict the outcome of an NBA game before it actually occurs. We can start with using a logistic regression model to get a probabilistic output but we can look into other classification models after we give this one a go. This article outlines the most imperative portion of a machine learning project, outlining the problem and preparing the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Data Exploration \n",
    "This post is a continuation of the data exploration post where we explored the 2017-2019 seasons for the Milwuakee Bucks and the Sacramento Kings. Feel free to hop out and pop back in if you want to see the data described and explored: \n",
    "\n",
    "[Part 1 post: Data Exploration with NBA Data](https://dpendleton22.github.io/valuebyerror/data%20exploration/box%20plots/histograms/nba/2020/01/14/nba-analysis-post.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![KeepItMoving](https://media.giphy.com/media/Ze4BXdrjDjygM9Piq0/giphy.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set all the necessary paths for the data \n",
    "The data was provided by https://www.basketball-reference.com/. They are a great source for anyone interested in sports analytics as an initial introduction. I can go into details later within the project to note the importance of detail in sports data.\n",
    "\n",
    "Using the <i>pathlib</i> library from pandas it's straightforward getting all the data file names set. Setting a base folder name is a good method to simply call each dataset path by their name. Another method to get each dataset path would be to use the <i>glob</i> library to search the dataset folder for files with csv extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse-hide\n",
    "DATA_FOLDER = Path(os.getcwd(), 'mil_sac_data')\n",
    "sac_2017_szn = Path(DATA_FOLDER, 'sac_2017_2018_szn.csv')\n",
    "sac_2018_szn = Path(DATA_FOLDER, 'sac_2018_2019_szn.csv')\n",
    "mil_2017_szn = Path(DATA_FOLDER, 'mil_2017_2018_szn.csv')\n",
    "mil_2018_szn = Path(DATA_FOLDER, 'mil_2018_2019_szn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's review one of the datasets to determine how they all need to be cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sac_2017_df = pd.read_csv(sac_2017_szn, header=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hold up, why are you setting the header argument?\n",
    "Most times than not, calling pd.read_csv(\"filename\") with no additional arguments would read in a dataframe as expected. In this instance, BasketballReference provides two headers in their csv so we need to let pandas know in order to process the dataset. Pandas read_csv() function has over 20 arguments that can be set depending on how the data is parsed and organized in the original file. So if your data is a little funky, the function may still be able to handle it.\n",
    "\n",
    "Pandas read_csv() documentation: [pandas.read_csv()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0_level_0</th>\n",
       "      <th>Unnamed: 1_level_0</th>\n",
       "      <th>Unnamed: 2_level_0</th>\n",
       "      <th>Unnamed: 3_level_0</th>\n",
       "      <th>Unnamed: 4_level_0</th>\n",
       "      <th>Unnamed: 5_level_0</th>\n",
       "      <th>Unnamed: 6_level_0</th>\n",
       "      <th>Unnamed: 7_level_0</th>\n",
       "      <th colspan=\"7\" halign=\"left\">Team</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Rk</th>\n",
       "      <th>G</th>\n",
       "      <th>Date</th>\n",
       "      <th>Unnamed: 3_level_1</th>\n",
       "      <th>Opp</th>\n",
       "      <th>W/L</th>\n",
       "      <th>Tm</th>\n",
       "      <th>Opp</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-10-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HOU</td>\n",
       "      <td>L</td>\n",
       "      <td>100</td>\n",
       "      <td>105</td>\n",
       "      <td>42</td>\n",
       "      <td>88</td>\n",
       "      <td>0.477</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>0.348</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-10-20</td>\n",
       "      <td>@</td>\n",
       "      <td>DAL</td>\n",
       "      <td>W</td>\n",
       "      <td>93</td>\n",
       "      <td>88</td>\n",
       "      <td>37</td>\n",
       "      <td>87</td>\n",
       "      <td>0.425</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>0.435</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-10-21</td>\n",
       "      <td>@</td>\n",
       "      <td>DEN</td>\n",
       "      <td>L</td>\n",
       "      <td>79</td>\n",
       "      <td>96</td>\n",
       "      <td>31</td>\n",
       "      <td>85</td>\n",
       "      <td>0.365</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>0.364</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-10-23</td>\n",
       "      <td>@</td>\n",
       "      <td>PHO</td>\n",
       "      <td>L</td>\n",
       "      <td>115</td>\n",
       "      <td>117</td>\n",
       "      <td>43</td>\n",
       "      <td>99</td>\n",
       "      <td>0.434</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>0.409</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-10-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOP</td>\n",
       "      <td>L</td>\n",
       "      <td>106</td>\n",
       "      <td>114</td>\n",
       "      <td>38</td>\n",
       "      <td>81</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>0.350</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0_level_0 Unnamed: 1_level_0 Unnamed: 2_level_0 Unnamed: 3_level_0  \\\n",
       "                  Rk                  G               Date Unnamed: 3_level_1   \n",
       "0                  1                  1         2017-10-18                NaN   \n",
       "1                  2                  2         2017-10-20                  @   \n",
       "2                  3                  3         2017-10-21                  @   \n",
       "3                  4                  4         2017-10-23                  @   \n",
       "4                  5                  5         2017-10-26                NaN   \n",
       "\n",
       "  Unnamed: 4_level_0 Unnamed: 5_level_0 Unnamed: 6_level_0 Unnamed: 7_level_0  \\\n",
       "                 Opp                W/L                 Tm                Opp   \n",
       "0                HOU                  L                100                105   \n",
       "1                DAL                  W                 93                 88   \n",
       "2                DEN                  L                 79                 96   \n",
       "3                PHO                  L                115                117   \n",
       "4                NOP                  L                106                114   \n",
       "\n",
       "  Team                                \n",
       "    FG FGA    FG%  3P 3PA    3P%  FT  \n",
       "0   42  88  0.477   8  23  0.348   8  \n",
       "1   37  87  0.425  10  23  0.435   9  \n",
       "2   31  85  0.365   8  22  0.364   9  \n",
       "3   43  99  0.434   9  22  0.409  20  \n",
       "4   38  81  0.469   7  20  0.350  23  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#collapse-show\n",
    "sac_2017_df.iloc[0:5, 0:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Tip: Always view the dimensions of your data before analyzing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset is 82 in length and contains 41 columns\n"
     ]
    }
   ],
   "source": [
    "print (f\"This dataset is {len(sac_2017_df)} in length and contains {len(sac_2017_df.columns)} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using df.describe() is an easy and useful way to briefly view the distribution of the dataset across all the columns. This dataset is 82 rows in length which makes sense because there are 82 games in a regular season and contains 41 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0_level_0</th>\n",
       "      <th>Unnamed: 1_level_0</th>\n",
       "      <th>Unnamed: 6_level_0</th>\n",
       "      <th>Unnamed: 7_level_0</th>\n",
       "      <th colspan=\"7\" halign=\"left\">Team</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Rk</th>\n",
       "      <th>G</th>\n",
       "      <th>Tm</th>\n",
       "      <th>Opp</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3P</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>98.600000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>38.200000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>0.434000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.381200</td>\n",
       "      <td>13.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.581139</td>\n",
       "      <td>1.581139</td>\n",
       "      <td>13.612494</td>\n",
       "      <td>12.144958</td>\n",
       "      <td>4.764452</td>\n",
       "      <td>6.708204</td>\n",
       "      <td>0.044486</td>\n",
       "      <td>1.140175</td>\n",
       "      <td>1.224745</td>\n",
       "      <td>0.038855</td>\n",
       "      <td>7.120393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>0.365000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.348000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>0.434000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.364000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>0.469000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.409000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>0.477000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.435000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0_level_0 Unnamed: 1_level_0 Unnamed: 6_level_0  \\\n",
       "                      Rk                  G                 Tm   \n",
       "count           5.000000           5.000000           5.000000   \n",
       "mean            3.000000           3.000000          98.600000   \n",
       "std             1.581139           1.581139          13.612494   \n",
       "min             1.000000           1.000000          79.000000   \n",
       "25%             2.000000           2.000000          93.000000   \n",
       "50%             3.000000           3.000000         100.000000   \n",
       "75%             4.000000           4.000000         106.000000   \n",
       "max             5.000000           5.000000         115.000000   \n",
       "\n",
       "      Unnamed: 7_level_0       Team                                  \\\n",
       "                     Opp         FG        FGA       FG%         3P   \n",
       "count           5.000000   5.000000   5.000000  5.000000   5.000000   \n",
       "mean          104.000000  38.200000  88.000000  0.434000   8.400000   \n",
       "std            12.144958   4.764452   6.708204  0.044486   1.140175   \n",
       "min            88.000000  31.000000  81.000000  0.365000   7.000000   \n",
       "25%            96.000000  37.000000  85.000000  0.425000   8.000000   \n",
       "50%           105.000000  38.000000  87.000000  0.434000   8.000000   \n",
       "75%           114.000000  42.000000  88.000000  0.469000   9.000000   \n",
       "max           117.000000  43.000000  99.000000  0.477000  10.000000   \n",
       "\n",
       "                                       \n",
       "             3PA       3P%         FT  \n",
       "count   5.000000  5.000000   5.000000  \n",
       "mean   22.000000  0.381200  13.800000  \n",
       "std     1.224745  0.038855   7.120393  \n",
       "min    20.000000  0.348000   8.000000  \n",
       "25%    22.000000  0.350000   9.000000  \n",
       "50%    22.000000  0.364000   9.000000  \n",
       "75%    23.000000  0.409000  20.000000  \n",
       "max    23.000000  0.435000  23.000000  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#collapse-hide\n",
    "sac_2017_df.iloc[0:5, 0:15].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge multi index headers and remove unwanted tags\n",
    "In stead of indexing by columns with this notation, \n",
    "```python\n",
    "sac_2017_df[('Unnamed: 0_level_0', 'Rk')]\n",
    "```\n",
    "we need to merge the header columns to allow for this type of indexing \n",
    "```python \n",
    "sac_2017_df['Rk']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets do a quick magic wave of the hand and merge these headers together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([('Unnamed: 5_level_0', 'W/L'),\n",
       "            ('Unnamed: 6_level_0',  'Tm'),\n",
       "            ('Unnamed: 7_level_0', 'Opp'),\n",
       "            (              'Team',  'FG'),\n",
       "            (              'Team', 'FGA'),\n",
       "            (              'Team', 'FG%'),\n",
       "            (              'Team',  '3P'),\n",
       "            (              'Team', '3PA'),\n",
       "            (              'Team', '3P%'),\n",
       "            (              'Team',  'FT')],\n",
       "           )"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sac_2017_df.columns[5:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_columns = sac_2017_df.columns.map('.'.join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![merging](https://media.giphy.com/media/NmerZ36iBkmKk/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 5_level_0.W/L', 'Unnamed: 6_level_0.Tm',\n",
       "       'Unnamed: 7_level_0.Opp', 'Team.FG', 'Team.FGA', 'Team.FG%', 'Team.3P',\n",
       "       'Team.3PA', 'Team.3P%', 'Team.FT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#collapse-hide\n",
    "merged_columns[5:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: Lets break that piece of code above down for a sec: <b>sac_2017_df.columns.map('.'.join)</b> is calling the [str.join()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.join.html) function where the str is '.' for each column with the [.map()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.map.html) function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with the columns merged, we can keep the prefixed descriptions such as Team and Opponent so we know whose stats we're viewing but prefixes like 'Unnamed: 0_level_0' are no use to us. \n",
    "\n",
    "We can use regular expressions to remove the unneeded text in some of our column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sac_2017_df.columns = merged_columns.str.replace(r\"Unnamed:\\ [0-9]_level_[0-9].\", '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rk</th>\n",
       "      <th>G</th>\n",
       "      <th>Date</th>\n",
       "      <th>Unnamed: 3_level_1</th>\n",
       "      <th>Opp</th>\n",
       "      <th>W/L</th>\n",
       "      <th>Tm</th>\n",
       "      <th>Opp</th>\n",
       "      <th>Team.FG</th>\n",
       "      <th>Team.FGA</th>\n",
       "      <th>Team.FG%</th>\n",
       "      <th>Team.3P</th>\n",
       "      <th>Team.3PA</th>\n",
       "      <th>Team.3P%</th>\n",
       "      <th>Team.FT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-10-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HOU</td>\n",
       "      <td>L</td>\n",
       "      <td>100</td>\n",
       "      <td>105</td>\n",
       "      <td>42</td>\n",
       "      <td>88</td>\n",
       "      <td>0.477</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>0.348</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-10-20</td>\n",
       "      <td>@</td>\n",
       "      <td>DAL</td>\n",
       "      <td>W</td>\n",
       "      <td>93</td>\n",
       "      <td>88</td>\n",
       "      <td>37</td>\n",
       "      <td>87</td>\n",
       "      <td>0.425</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>0.435</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-10-21</td>\n",
       "      <td>@</td>\n",
       "      <td>DEN</td>\n",
       "      <td>L</td>\n",
       "      <td>79</td>\n",
       "      <td>96</td>\n",
       "      <td>31</td>\n",
       "      <td>85</td>\n",
       "      <td>0.365</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>0.364</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-10-23</td>\n",
       "      <td>@</td>\n",
       "      <td>PHO</td>\n",
       "      <td>L</td>\n",
       "      <td>115</td>\n",
       "      <td>117</td>\n",
       "      <td>43</td>\n",
       "      <td>99</td>\n",
       "      <td>0.434</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>0.409</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-10-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOP</td>\n",
       "      <td>L</td>\n",
       "      <td>106</td>\n",
       "      <td>114</td>\n",
       "      <td>38</td>\n",
       "      <td>81</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>0.350</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rk  G        Date Unnamed: 3_level_1  Opp W/L   Tm  Opp  Team.FG  Team.FGA  \\\n",
       "0   1  1  2017-10-18                NaN  HOU   L  100  105       42        88   \n",
       "1   2  2  2017-10-20                  @  DAL   W   93   88       37        87   \n",
       "2   3  3  2017-10-21                  @  DEN   L   79   96       31        85   \n",
       "3   4  4  2017-10-23                  @  PHO   L  115  117       43        99   \n",
       "4   5  5  2017-10-26                NaN  NOP   L  106  114       38        81   \n",
       "\n",
       "   Team.FG%  Team.3P  Team.3PA  Team.3P%  Team.FT  \n",
       "0     0.477        8        23     0.348        8  \n",
       "1     0.425       10        23     0.435        9  \n",
       "2     0.365        8        22     0.364        9  \n",
       "3     0.434        9        22     0.409       20  \n",
       "4     0.469        7        20     0.350       23  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sac_2017_df.iloc[0:5, 0:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is still an 'Unnmaed: 3_level_1' tag after the regex processing which represents if the team of interest was playing home or away. We won't even be using this column as is so we can just process our new column and drop 'Unnamed: 3_level_1' after.\n",
    "\n",
    "The existing column consists of discreet values 'NaN' or @ indication if the team was playing at home or away for this instance. We can simply check if the row value is NaN using the .isnull() function in pandas and set those values as a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sac_2017_df['playing_home'] = sac_2017_df['Unnamed: 3_level_1'].isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our column we can simply drop the existing \"Unnamed: 3_level_1\" column because \"playing_home\" represents the same thing now but with true and false values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "sac_2017_df.drop(columns=['Unnamed: 3_level_1'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rk</th>\n",
       "      <th>G</th>\n",
       "      <th>Date</th>\n",
       "      <th>Unnamed: 3_level_1</th>\n",
       "      <th>Opp</th>\n",
       "      <th>W/L</th>\n",
       "      <th>Tm</th>\n",
       "      <th>Opp</th>\n",
       "      <th>Team.FG</th>\n",
       "      <th>Team.FGA</th>\n",
       "      <th>Team.FG%</th>\n",
       "      <th>Team.3P</th>\n",
       "      <th>Team.3PA</th>\n",
       "      <th>Team.3P%</th>\n",
       "      <th>Team.FT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-10-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HOU</td>\n",
       "      <td>L</td>\n",
       "      <td>100</td>\n",
       "      <td>105</td>\n",
       "      <td>42</td>\n",
       "      <td>88</td>\n",
       "      <td>0.477</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>0.348</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-10-20</td>\n",
       "      <td>@</td>\n",
       "      <td>DAL</td>\n",
       "      <td>W</td>\n",
       "      <td>93</td>\n",
       "      <td>88</td>\n",
       "      <td>37</td>\n",
       "      <td>87</td>\n",
       "      <td>0.425</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>0.435</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-10-21</td>\n",
       "      <td>@</td>\n",
       "      <td>DEN</td>\n",
       "      <td>L</td>\n",
       "      <td>79</td>\n",
       "      <td>96</td>\n",
       "      <td>31</td>\n",
       "      <td>85</td>\n",
       "      <td>0.365</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>0.364</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-10-23</td>\n",
       "      <td>@</td>\n",
       "      <td>PHO</td>\n",
       "      <td>L</td>\n",
       "      <td>115</td>\n",
       "      <td>117</td>\n",
       "      <td>43</td>\n",
       "      <td>99</td>\n",
       "      <td>0.434</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>0.409</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-10-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOP</td>\n",
       "      <td>L</td>\n",
       "      <td>106</td>\n",
       "      <td>114</td>\n",
       "      <td>38</td>\n",
       "      <td>81</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>0.350</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rk  G        Date Unnamed: 3_level_1  Opp W/L   Tm  Opp  Team.FG  Team.FGA  \\\n",
       "0   1  1  2017-10-18                NaN  HOU   L  100  105       42        88   \n",
       "1   2  2  2017-10-20                  @  DAL   W   93   88       37        87   \n",
       "2   3  3  2017-10-21                  @  DEN   L   79   96       31        85   \n",
       "3   4  4  2017-10-23                  @  PHO   L  115  117       43        99   \n",
       "4   5  5  2017-10-26                NaN  NOP   L  106  114       38        81   \n",
       "\n",
       "   Team.FG%  Team.3P  Team.3PA  Team.3P%  Team.FT  \n",
       "0     0.477        8        23     0.348        8  \n",
       "1     0.425       10        23     0.435        9  \n",
       "2     0.365        8        22     0.364        9  \n",
       "3     0.434        9        22     0.409       20  \n",
       "4     0.469        7        20     0.350       23  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sac_2017_df.iloc[0:5, 0:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to prepare this data for a logistic regression model, we will also need to convert the non-numeric columns we plan to use to numerical values. Specifically converting the column of interest \"W/L\" to a numeric representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sac_2017_df['dub'] = sac_2017_df['W/L'] == 'W'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True values in this new column represent the team of interest got the dub or the Wu as Mastah Killah would say #WuTang #ATLUnited\n",
    "![Wu](https://media.giphy.com/media/2sceLbzj36eSxvcsYo/giphy.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Opponent.FTA</th>\n",
       "      <th>Opponent.FT%</th>\n",
       "      <th>Opponent.ORB</th>\n",
       "      <th>Opponent.TRB</th>\n",
       "      <th>Opponent.AST</th>\n",
       "      <th>Opponent.STL</th>\n",
       "      <th>Opponent.BLK</th>\n",
       "      <th>Opponent.TOV</th>\n",
       "      <th>Opponent.PF</th>\n",
       "      <th>dub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>0.931</td>\n",
       "      <td>12</td>\n",
       "      <td>44</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>0.714</td>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>0.600</td>\n",
       "      <td>18</td>\n",
       "      <td>58</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>0.852</td>\n",
       "      <td>6</td>\n",
       "      <td>45</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>0.739</td>\n",
       "      <td>10</td>\n",
       "      <td>47</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Opponent.FTA  Opponent.FT%  Opponent.ORB  Opponent.TRB  Opponent.AST  \\\n",
       "0            29         0.931            12            44            19   \n",
       "1            21         0.714             7            36            19   \n",
       "2            20         0.600            18            58            25   \n",
       "3            27         0.852             6            45            20   \n",
       "4            23         0.739            10            47            22   \n",
       "\n",
       "   Opponent.STL  Opponent.BLK  Opponent.TOV  Opponent.PF    dub  \n",
       "0             7             3            14           14  False  \n",
       "1             8             7            12           13   True  \n",
       "2             7             2            16           19  False  \n",
       "3             6             5            20           25  False  \n",
       "4             5             3            15           24  False  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sac_2017_df.iloc[0:5, -10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Might as well make a pipeline\n",
    "We have established, at least, our first pass at preparing the dataset. Since we will have to prepare the other dataframes in a similar way we can mitigate this by creating a data pipeline. This pipeline will take each original dataframe in and run the same preprocessing steps. This ensures everything is going through the same steps. Pipelines are not required but it will help you to stay organized \n",
    "\n",
    "To make a pipeline we'll need to make the previous steps we created into a function to pass each dataframe through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pipeline(df):\n",
    "    test = df.columns.map('.'.join).str.strip('.')\n",
    "    df.columns = test.str.replace(r\"Unnamed:\\ [0-9]_level_[0-9].\", '', regex=True)\n",
    "    df['playing_home'] = df['Unnamed: 3_level_1'].isnull()\n",
    "    df.drop(columns=['Unnamed: 3_level_1'], inplace=True)\n",
    "    df['dub'] = df['W/L'] == 'W'\n",
    "    df.drop(columns=['W/L'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the pipeline\n",
    "We can consolidate the number of duplicate lines to run into a function and process all similar datasets with the same function. The code below reads in each dataset and immediately uses the pandas .pipe() function passing in the preprocessing function. Though we didn't use it, the [pandas.DataFrame.pipe()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pipe.html?highlight=pipe#pandas.DataFrame.pipe) function allows positional and keyword arguments to be passed in with the function to run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "sac_2017_df = pd.read_csv(sac_2017_szn, header=[0, 1]).pipe(data_pipeline)\n",
    "sac_2018_df = pd.read_csv(sac_2018_szn, header=[0, 1]).pipe(data_pipeline)\n",
    "mil_2017_df = pd.read_csv(mil_2017_szn, header=[0, 1]).pipe(data_pipeline)\n",
    "mil_2018_df = pd.read_csv(mil_2018_szn, header=[0, 1]).pipe(data_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Jist\n",
    "Data cleaning and preprocessing is not the most fun job in data science but it sets the foundation for whatever model that will be used. There are a number of automated tools and software that claim to automatically clean datasets but from this notebook it's easy to see it isn't a cookie cutter process. This dataset was cleaned knowing a logistic regression model was going to be used and the tags to fit the model but various other methods could have been used to clean this data. Such as scaling the dataset or one-hot encoding all string columns (but I plan to not use most of them so I didn't bother). An experienced engineer once told me coding should be the easy part. That statement didn't hit me at first but I now understand that statement speaks to the importance of understanding what you want to do with the data or a model. Speaking of model, in the next post we'll get right into logistic regression models and how to measure their success cause\n",
    "![obama](https://media.giphy.com/media/C7vI9SlliHtp6o478J/giphy.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
